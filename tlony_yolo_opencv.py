import argparse
import logging
import os
import zipfile
from pathlib import Path
from typing import Optional

import cv2
from huggingface_hub import hf_hub_download
from ultralytics import YOLO

from tlony_core import DATASET_FILENAME, DATASET_REPO_ID, TLONY_CLASSES, interpret_condition

logger = logging.getLogger(__name__)


# ==========================
# 1. DESCARGA + PREPARACIÓN
# ==========================


def configure_logging(verbose: bool = False) -> None:
    """
    Configura logging básico compatible con scripts y notebooks.
    """
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(level=level, format="[%(levelname)s] %(message)s")


def dataset_is_ready(dataset_root_path: Path) -> bool:
    """
    Determina si ya existe una copia extraída del dataset en dataset_root_path.
    """
    candidate_bases = [dataset_root_path / "tlony", dataset_root_path]
    possible_dirs = []
    for base in candidate_bases:
        if not base.exists():
            continue
        possible_dirs.extend(
            [
                base / "train" / "images",
                base / "data" / "images" / "train",
                base / "images" / "train",
            ]
        )
    return any(path.exists() for path in possible_dirs)

def find_tlony_root(dataset_root: Path) -> Path:
    """
    Devuelve la carpeta principal de TLoNY dentro de dataset_root.
    Normalmente será dataset_root / 'tlony', pero si no existe,
    usamos dataset_root directamente.
    """
    tlony_dir = dataset_root / "tlony"
    if tlony_dir.exists():
        return tlony_dir
    # fallback: por si el zip se descomprime sin carpeta 'tlony'
    return dataset_root


def create_fixed_tlony_yaml(tlony_dir: Path) -> Path:
    """
    Busca automáticamente las carpetas de imágenes/labels y crea
    un data.yaml NUEVO y correcto para YOLOv8, ignorando el que
    viene dentro del zip.
    Soporta tanto:
        tlony/train/images
        tlony/train/labels
    como:
        tlony/data/images/train
        tlony/data/labels/train
    """

    # Posibles ubicaciones para imágenes de train
    possible_train_imgs = [
        tlony_dir / "train" / "images",
        tlony_dir / "data" / "images" / "train",
        tlony_dir / "images" / "train",
    ]
    train_imgs = next((p for p in possible_train_imgs if p.exists()), None)

    if train_imgs is None:
        raise FileNotFoundError(
            "No se encontró la carpeta de imágenes de entrenamiento.\n"
            f"Probé:\n  - {possible_train_imgs[0]}\n"
            f"  - {possible_train_imgs[1]}\n"
            f"  - {possible_train_imgs[2]}\n"
            "Revisa con 'tree' dónde quedaron exactamente las imágenes."
        )

    # Posibles ubicaciones para labels de train
    possible_train_labels = [
        tlony_dir / "train" / "labels",
        tlony_dir / "data" / "labels" / "train",
        tlony_dir / "labels" / "train",
    ]
    train_labels = next((p for p in possible_train_labels if p.exists()), None)

    if train_labels is None:
        raise FileNotFoundError(
            "No se encontró la carpeta de labels de entrenamiento que coincida con las imágenes.\n"
            f"Probé:\n  - {possible_train_labels[0]}\n"
            f"  - {possible_train_labels[1]}\n"
            f"  - {possible_train_labels[2]}"
        )

    # Posibles ubicaciones para imágenes de validación
    possible_val_imgs = [
        tlony_dir / "val" / "images",
        tlony_dir / "data" / "images" / "val",
        tlony_dir / "images" / "val",
    ]
    val_imgs = next((p for p in possible_val_imgs if p.exists()), None)

    if val_imgs is None:
        # Si no hay val, usamos train también como val (solo para demo)
        val_imgs = train_imgs
        logger.warning("No se encontró conjunto de validación; usaré TRAIN también como VAL.")

    train_imgs_abs = train_imgs.resolve()
    val_imgs_abs = val_imgs.resolve()

    yaml_path = tlony_dir / "tlony_yolo_fixed.yaml"

    # IMPORTANTE:
    # Usamos rutas ABSOLUTAS a las carpetas de IMÁGENES.
    # YOLO derivará las rutas de LABELS sustituyendo 'images' por 'labels'.
    yaml_text = f"""# Auto-generated by tlony_yolo_opencv.py
# Dataset: Traffic Lights of New York (TLoNY)
# Este archivo ignora el data.yaml original del zip y usa rutas reales en tu disco.

path: .
train: {train_imgs_abs.as_posix()}
val: {val_imgs_abs.as_posix()}
nc: 8
names:
  0: red
  1: green
  2: yellow
  3: red+yellow
  4: unknown
  5: pedred
  6: pedgreen
  7: pedunknown
"""

    yaml_path.write_text(yaml_text, encoding="utf-8")

    logger.info("Archivo de configuración YOLO creado/corregido en %s", yaml_path)
    logger.info("train dir : %s", train_imgs_abs)
    logger.info("val dir   : %s", val_imgs_abs)
    return yaml_path


def download_and_prepare_tlony(dataset_root: str = "data", force_download: bool = False) -> str:
    """
    Descarga tlony.zip desde HuggingFace, lo descomprime en dataset_root
    y crea un data.yaml NUEVO (tlony_yolo_fixed.yaml) que apunta a las
    rutas reales de imágenes y labels.
    """
    dataset_root_path = Path(dataset_root)
    dataset_root_path.mkdir(parents=True, exist_ok=True)

    needs_download = force_download or not dataset_is_ready(dataset_root_path)

    if needs_download:
        logger.info("Descargando %s desde Hugging Face (se usa caché local si existe)...", DATASET_FILENAME)
        try:
            zip_path = hf_hub_download(
                repo_id=DATASET_REPO_ID,
                filename=DATASET_FILENAME,
                repo_type="dataset",
            )
        except Exception as exc:
            raise RuntimeError(
                "No se pudo descargar el dataset TLoNY. Verifica tu conexión o token de Hugging Face."
            ) from exc

        logger.info("Descomprimiendo %s en %s ...", DATASET_FILENAME, dataset_root_path)
        with zipfile.ZipFile(zip_path, "r") as zf:
            # Extrae, pero si ya existen archivos no pasa nada
            zf.extractall(dataset_root_path)
    else:
        logger.info("Se detectó una copia existente de TLoNY en %s; omito descarga.", dataset_root_path)

    tlony_dir = find_tlony_root(dataset_root_path)
    logger.info("Directorio base de TLoNY detectado en: %s", tlony_dir)

    data_yaml_path = create_fixed_tlony_yaml(tlony_dir)
    return str(data_yaml_path)


# ==========================
# 2. ENTRENAMIENTO YOLOv8
# ==========================

def train_yolo_tlony(
    data_yaml_path: str,
    model_size: str = "n",
    epochs: int = 60,
    imgsz: int = 640,
    batch: int = 16,
    device: Optional[str] = None,
) -> str:
    """
    Entrena YOLOv8 (por defecto yolov8n) sobre TLoNY usando el YAML corregido.
    """
    pretrained_weights = f"yolov8{model_size}.pt"
    logger.info("Cargando modelo pre-entrenado: %s", pretrained_weights)
    model = YOLO(pretrained_weights)

    logger.info(
        "Iniciando entrenamiento en TLoNY (epochs=%d, imgsz=%d, batch=%d, device=%s)",
        epochs,
        imgsz,
        batch,
        device or "auto",
    )
    results = model.train(
        data=data_yaml_path,
        imgsz=imgsz,
        epochs=epochs,
        batch=batch,
        project="runs/tlony",
        name=f"yolov8{model_size}-tlony",
        exist_ok=True,
        device=device,
    )

    best_weights = Path(results.save_dir) / "weights" / "best.pt"
    logger.info("Entrenamiento completado. Pesos guardados en: %s", best_weights)
    return str(best_weights)


# ==========================
# 3. DETECCIÓN + OPENCV
# ==========================

TLOGY_CLASSES = [
    "red",          # 0
    "green",        # 1
    "yellow",       # 2
    "red+yellow",   # 3
    "unknown",      # 4
    "pedred",       # 5
    "pedgreen",     # 6
    "pedunknown",   # 7
]


def interpret_condition(class_name: str) -> str:
    mapping = {
        "red": "Semáforo vehicular en ROJO",
        "green": "Semáforo vehicular en VERDE",
        "yellow": "Semáforo vehicular en AMARILLO",
        "red+yellow": "Semáforo vehicular en ROJO+AMARILLO",
        "unknown": "Semáforo vehicular (color desconocido)",
        "pedred": "Semáforo PEATONAL en ROJO (No caminar)",
        "pedgreen": "Semáforo PEATONAL en VERDE (Caminar)",
        "pedunknown": "Semáforo PEATONAL (color desconocido)",
    }
    return mapping.get(class_name, class_name)


def detect_traffic_lights(
    image_path: str,
    weights_path: str,
    conf_thres: float = 0.4,
    save_path: Optional[str] = None,
    show_window: bool = True,
):
    """
    Carga una imagen con OpenCV, ejecuta el modelo YOLOv8 entrenado en TLoNY,
    dibuja las detecciones y muestra la condición del semáforo.
    """
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"No se pudo cargar la imagen: {image_path}")

    logger.info("Cargando pesos entrenados: %s", weights_path)
    model = YOLO(weights_path)

    logger.info("Corriendo inferencia sobre %s (conf=%.2f)...", image_path, conf_thres)
    results = model.predict(source=img, conf=conf_thres, verbose=False)

    annotated = img.copy()
    h, w = annotated.shape[:2]
    detections_info = []

    for r in results:
        for box in r.boxes:
            cls_id = int(box.cls[0].item())
            conf = float(box.conf[0].item())
            x1, y1, x2, y2 = box.xyxy[0].tolist()

            x1 = max(0, min(int(x1), w - 1))
            y1 = max(0, min(int(y1), h - 1))
            x2 = max(0, min(int(x2), w - 1))
            y2 = max(0, min(int(y2), h - 1))

            class_name = TLOGY_CLASSES[cls_id] if 0 <= cls_id < len(TLOGY_CLASSES) else str(cls_id)
            condition_text = interpret_condition(class_name)

            detections_info.append((class_name, condition_text, conf, (x1, y1, x2, y2)))

            # dibujar caja
            cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{class_name} {conf:.2f}"

            (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(annotated, (x1, y1 - th - 4), (x1 + tw, y1), (0, 255, 0), -1)
            cv2.putText(
                annotated, label, (x1, y1 - 2),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1
            )

    if not detections_info:
        logger.warning("No se detectaron semáforos en la imagen.")
    else:
        logger.info("Detecciones encontradas:")
        for i, (cls_name, cond_text, conf, (x1, y1, x2, y2)) in enumerate(detections_info, start=1):
            logger.info(
                "  #%d: %s (clase=%s, conf=%.2f, bbox=(%d,%d,%d,%d))",
                i,
                cond_text,
                cls_name,
                conf,
                x1,
                y1,
                x2,
                y2,
            )

    if save_path:
        cv2.imwrite(save_path, annotated)
        logger.info("Imagen anotada guardada en %s", save_path)

    if show_window:
        cv2.imshow("Detección de semáforos (TLoNY + YOLOv8)", annotated)
        logger.info("Presiona cualquier tecla en la ventana para cerrar.")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    else:
        logger.info("Visualización deshabilitada (modo headless).")


# ==========================
# 4. CLI
# ==========================


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description=(
            "Descarga y prepara TLoNY, entrena YOLOv8 y prueba rápidamente "
            "el modelo con una imagen estática."
        )
    )
    parser.add_argument(
        "--image",
        type=str,
        help="Ruta a la fotografía del semáforo que quieres analizar (ej: ./001.jpg).",
    )
    parser.add_argument(
        "--dataset_root",
        type=str,
        default="data",
        help="Directorio donde se extrae tlony.zip (por defecto: ./data).",
    )
    parser.add_argument(
        "--train",
        action="store_true",
        help="Si se indica, entrena el modelo antes de realizar la detección.",
    )
    parser.add_argument(
        "--weights",
        type=str,
        default="runs/tlony/yolov8n-tlony/weights/best.pt",
        help="Ruta a los pesos entrenados (si ya los tienes y no quieres re-entrenar).",
    )
    parser.add_argument(
        "--model_size",
        type=str,
        default="n",
        choices=["n", "s", "m", "l", "x"],
        help="Tamaño base del modelo YOLOv8 a entrenar.",
    )
    parser.add_argument(
        "--epochs",
        type=int,
        default=60,
        help="Número de épocas para el entrenamiento.",
    )
    parser.add_argument(
        "--imgsz",
        type=int,
        default=640,
        help="Resolución (lado) usada por YOLOv8 durante el entrenamiento.",
    )
    parser.add_argument(
        "--batch",
        type=int,
        default=16,
        help="Batch size para YOLOv8.",
    )
    parser.add_argument(
        "--device",
        type=str,
        help="Dispositivo para entrenar/inferir (ej: cuda:0 o cpu). Si se omite se auto-detecta.",
    )
    parser.add_argument(
        "--conf",
        type=float,
        default=0.4,
        help="Umbral de confianza para la inferencia en la imagen de prueba.",
    )
    parser.add_argument(
        "--force_download",
        action="store_true",
        help="Fuerza la descarga/descompresión del dataset incluso si detectamos uno existente.",
    )
    parser.add_argument(
        "--prepare_only",
        action="store_true",
        help="Solo prepara el dataset (descarga + YAML) y termina.",
    )
    parser.add_argument(
        "--save_path",
        type=str,
        help="Ruta donde guardar la imagen anotada tras la detección.",
    )
    parser.add_argument(
        "--headless",
        action="store_true",
        help="Desactiva cv2.imshow (útil para servidores sin entorno gráfico).",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Activa logging detallado (DEBUG).",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    configure_logging(args.verbose)

    data_yaml = download_and_prepare_tlony(args.dataset_root, force_download=args.force_download)
    logger.info("Archivo data.yaml consolidado en: %s", data_yaml)

    if args.prepare_only:
        logger.info("Se solicitó --prepare_only. Finalizando tras preparar el dataset.")
        return

    # 2) Entrenar (opcional) o reutilizar pesos existentes
    if args.train:
        best_weights = train_yolo_tlony(
            data_yaml_path=data_yaml,
            model_size=args.model_size,
            epochs=args.epochs,
            imgsz=args.imgsz,
            batch=args.batch,
            device=args.device,
        )
    else:
        best_weights = args.weights
        if not os.path.exists(best_weights):
            raise FileNotFoundError(
                f"No se encontró el archivo de pesos: {best_weights}\n"
                "Ejecuta de nuevo con --train para entrenar un modelo."
            )

    # 3) Detectar en la imagen nueva
    if args.image:
        image_path = Path(args.image)
        if not image_path.exists():
            raise FileNotFoundError(f"No se encontró la imagen de prueba: {image_path}")

        detect_traffic_lights(
            image_path=str(image_path),
            weights_path=best_weights,
            conf_thres=args.conf,
            save_path=args.save_path,
            show_window=not args.headless,
        )
    else:
        logger.info("No se proporcionó --image; se omite la inferencia de prueba.")


if __name__ == "__main__":
    main()
